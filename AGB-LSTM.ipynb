{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from spektral.layers import GINConv\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "seed = 2024\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "time_str = now.strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6a92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "\n",
    "folder_names = [f'models/{time_str}', f'history/{time_str}']  \n",
    "for folder_path in folder_names:  \n",
    "    if not os.path.exists(folder_path):  \n",
    "        os.makedirs(folder_path)  \n",
    "        print(f"Folder {folder_path} created successfully.")  \n",
    "    else:  \n",
    "        print(f"Folder {folder_path} already exists.")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_start = 3\n",
    "time_steps_end = 15\n",
    "time_steps = time_steps_end - time_steps_start + 1\n",
    "feature_count = 7  \n",
    "threshold = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('6.25~8.24 train.csv', encoding='GBK')\n",
    "df_train = df_train.sort_values(by=['YEAR','COUNTY','INDEX'])\n",
    "sequences_list = []\n",
    "labels_list = []\n",
    "for state, group in df_train.groupby(['COUNTY']):\n",
    "    sequences = group.iloc[:, time_steps_start:time_steps_end+1].values.reshape(-1, feature_count, time_steps).transpose(0, 2, 1)\n",
    "    labels = group.iloc[::feature_count, 16].values \n",
    "    sequences_list.append(sequences)\n",
    "    labels_list.append(labels)\n",
    "X_train = np.concatenate(sequences_list, axis=0)\n",
    "y_train = np.concatenate(labels_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_csv('6.25~8.24 test.csv', encoding='gbk')\n",
    "df_predict = df_predict.sort_values(by=['YEAR','COUNTY','INDEX'])\n",
    "sequences_list = []\n",
    "labels_list = []\n",
    "\n",
    "for state, group in df_predict.groupby(['COUNTY']):\n",
    "    sequences = group.iloc[:, time_steps_start:time_steps_end+1].values.reshape(-1, feature_count, time_steps).transpose(0, 2, 1)\n",
    "    labels = group.iloc[::feature_count, 16].values \n",
    "    sequences_list.append(sequences)\n",
    "    labels_list.append(labels)\n",
    "X_test = np.concatenate(sequences_list, axis=0)\n",
    "y_test = np.concatenate(labels_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler_y_train = scaler.fit_transform(y_train.reshape(-1,1))\n",
    "scaler_y_test = scaler.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308482c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, n, c = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a1ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train['INDEX'].unique():\n",
    "    col_df[col] = df_train[df_train['INDEX'] == col].values[:, time_steps_start:time_steps_end+1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = col_df.astype(float).corr().values\n",
    "rows, cols = np.where(A != 0)\n",
    "values = A[rows, cols]\n",
    "A = tf.SparseTensor(indices=list(zip(rows.tolist(), cols.tolist())), \n",
    "                                values=values.tolist(), \n",
    "                                dense_shape=A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baeb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(Model): \n",
    "    def __init__(self,out_size,hidden_num,hidden_size,A):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.A = A\n",
    "        self.hidden_num = hidden_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gin = GINConv(out_size, mlp_hidden=[hidden_num,hidden_size], activation='relu')\n",
    "    def call(self, inputs):\n",
    "        x_gin = GINConv(self.out_size, mlp_hidden=[self.hidden_num,self.hidden_size], activation='relu')([inputs, self.A])\n",
    "        return x_gin\n",
    "    def get_config(self):\n",
    "        return {\"out_size\": self.out_size,\n",
    "                 \"A\": self.A,\n",
    "                 \"hidden_num\": self.hidden_num,\n",
    "                 \"hidden_size\": self.hidden_size\n",
    "               }\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model(hidden_num,hidden_size,dense_size,dropout,hidden=1):\n",
    "    x_in = Input((n, c), name='input')\n",
    "    x_gin = GINConv(c, mlp_hidden=[hidden_num,hidden_size], activation='relu')([x_in, A])  # mlp_hidden：隐藏层数=2，隐藏层大小=16\n",
    "    x = Attention()([x_in,x_gin])\n",
    "    x = Bidirectional(LSTM(11 * hidden, return_sequences=True))(x) \n",
    "    x = LSTM(11 * hidden, return_sequences=True)(x) \n",
    "    x = Attention()([x,x])  \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(dense_size)(x)\n",
    "    x = Dropout(rate=dropout)(x) \n",
    "    out = Dense(1)(x)\n",
    "    model = Model(x_in,out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.1,0.2,0.3,0.4,0.5])\n",
    "    #hidden = trial.suggest_int('hidden',16,256) \n",
    "    hidden = trial.suggest_int('hidden',1,20) \n",
    "    learning_rate = trial.suggest_float('learning_rate',0.0001,0.1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size',[16,32,64,128])\n",
    "    dense_size = trial.suggest_int('dense_size',8,256) \n",
    "    hidden_num = trial.suggest_int('hidden_num',1,16)\n",
    "    hidden_size = trial.suggest_int('hidden_size',16,256) \n",
    "    model = creat_model(hidden_num,hidden_size,dense_size,dropout,hidden)\n",
    "    adam = Adam(learning_rate=learning_rate)  # adam 学习率learning_rate=0.0001\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "    path = f\"{time_str}_{hidden}_{batch_size}_{dense_size}_{learning_rate}.weights.h5\"\n",
    "    model_path = f'models/{time_str}/' + path\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=0,\n",
    "                                                    save_best_only=True, mode='min', save_weights_only=True)\n",
    "    history = model.fit(X_train,scaler_y_train, \n",
    "                        epochs=50, batch_size=batch_size, \n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[checkpoint], \n",
    "                        #callbacks=[checkpoint, earlyStop], \n",
    "                        verbose=1, shuffle=True)\n",
    "    with open(f\"./history/{time_str}/history_{path.split('.')[0]}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(history.history, f)    \n",
    "    model.load_weights(model_path)\n",
    "    y_pred=scaler.inverse_transform(model.predict(X_test))\n",
    "    pred_r2 = r2_score(y_test,y_pred)\n",
    "    return pred_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454bf0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_trial.params\n",
    "best_params.update({'R2':study.best_trial.value})\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(f'./trials/{time_str}_trials_dataframe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3aeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = creat_model(best_params['hidden_num'],\n",
    "                    best_params['hidden_size'],\n",
    "                    best_params['dense_size'],\n",
    "                    best_params['dropout'],\n",
    "                    best_params['hidden'])\n",
    "\n",
    "adam = Adam(learning_rate=best_params['learning_rate'])  # adam 学习率learning_rate=0.0001\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5dea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = f\"./models/{time_str}/{time_str}_{best_params['hidden']}_{best_params['batch_size']}_{best_params['dense_size']}_{best_params['learning_rate']}.weights.h5\"\n",
    "model.load_weights(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} training samples\".format(y_train.shape[0]))\n",
    "print(\"There are {} testing samples\".format(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_his(history):\n",
    "    # plot history\n",
    "    # history.history\n",
    "    plt.plot(history['loss'], label='train loss')\n",
    "    plt.plot(history['val_loss'], label='val loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    \n",
    "def evaluate(y, pred, model = 'model',mode='test',is_weight=False):\n",
    "    mse = mean_squared_error(y, pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, pred) \n",
    "    r2 = r2_score(y, pred)\n",
    "    mape = mean_absolute_percentage_error(y, pred)\n",
    "    print(f'{model}: MSE \\t{mode}:{mse:.4f}\\n{model}: RMSE\\t{mode}:{rmse:.4f}\\n{model}: MAE\\t{mode}:{mae:.4f}')\n",
    "    if is_weight:\n",
    "        # 样本误差权重设置\n",
    "        wmape = mean_absolute_percentage_error(y, pred,multioutput=[0.4,0.4,0.2])\n",
    "        print(f'{model}: R2 \\t{mode}:{r2:.4f}\\n{model}: MAPE\\t{mode}:{mape:.4f}\\n{model}: WMAPE\\t{mode}:{wmape:.4f}')\n",
    "    else:\n",
    "        print(f'{model}: R2 \\t{mode}:{r2:.4f}\\n{model}: MAPE\\t{mode}:{mape:.4f}')\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f95be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_path = f\"./history/{time_str}/history_{best_model.split('/')[-1].split('.')[0]}.pkl\"\n",
    "with open(his_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "plot_his(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X_test)\n",
    "r2 = evaluate(y_test, scaler.inverse_transform(pred_y.reshape(-1,1)), is_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_names = 'GINConv-Attention-Lstm-Attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21372b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "test_y = y_test\n",
    "result=pd.DataFrame()\n",
    "result['pred']=scaler.inverse_transform(yhat[:,0].reshape(-1,1))[:,0]\n",
    "result['real']=scaler.inverse_transform(scaler_y_test).reshape(-1,1)[:,0]\n",
    "result.to_csv(f'{y_names}_scatter_data.csv', index=False)\n",
    "result.head(50).plot(figsize=(15,9),style=['*r','-b'])\n",
    "plt.title(f\"\"\"Predicted vs Actual for {y_names}\"\"\")\n",
    "plt.xlabel('Sample Number')\n",
    "plt.ylabel('Values')\n",
    "plt.savefig(f'{y_names}_Predicted vs Actual Mult.svg',dpi=300, bbox_inches = 'tight')\n",
    "plt.show();\n",
    "plt.scatter(result['real'], result['pred'], color='blue')\n",
    "plt.plot([result['real'].min(), result['real'].max()], [result['real'].min(), result['real'].max()], 'k--', lw=2,color='r')\n",
    "plt.title(f\"\"\"Predicted vs Actual Estimated Total Cost {y_names} (R2 = {r2:.4f})\"\"\")\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{y_names}_final_models_2 Mult.svg',dpi=300, bbox_inches = 'tight')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5

}
